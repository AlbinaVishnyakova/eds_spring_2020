{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дайте мне таблетки от жадности! И побольше, побольше!\n",
    "\n",
    "![](https://cs4.pikabu.ru/post_img/2016/08/12/8/1471008417115067244.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats # more style :)\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')  # стиль для графиков\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задаченька 1. Функция-няша и функция-бяка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а) Найдите минимум фукнции $f(x_1, x_2) = (x_1 - 2)^2 + (x_2 - 4)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 9.095763293783874e-17\n",
       " hess_inv: array([[ 0.9, -0.2],\n",
       "       [-0.2,  0.6]])\n",
       "      jac: array([ 6.37085673e-09, -2.15944951e-09])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 16\n",
       "      nit: 3\n",
       "     njev: 4\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([2.        , 3.99999999])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(x):\n",
    "    \"\"\" какая-то приятная функция \"\"\"\n",
    "    z = (x[0] - 2) ** 2 + (x[1] - 4) ** 2\n",
    "    return z\n",
    "\n",
    "x_init = [0, 0]\n",
    "optim_res = minimize(fun, x_init)\n",
    "optim_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.        , 3.99999999]), 9.095763293783874e-17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_res.x, optim_res.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим в функцию параметр $a$: $f(x_1, x_2) = (x_1 - 2a)^2 + (x_2 - 4)^2$\n",
    "\n",
    "б) Найдите экстремум функции при $a=4$ и при $a=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 3.131976557517399e-12\n",
       " hess_inv: array([[ 0.59999985, -0.19999989],\n",
       "       [-0.19999989,  0.90000014]])\n",
       "      jac: array([-1.60278948e-06,  3.16307257e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 20\n",
       "      nit: 4\n",
       "     njev: 5\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([7.99999919, 4.00000157])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(x, a):\n",
    "    \"\"\" какая-то приятная функция \"\"\"\n",
    "    z = (x[0] - 2 * a) ** 2 + (x[1] - 4) ** 2\n",
    "    return z\n",
    "\n",
    "x_init = [0, 0]\n",
    "optim_res = minimize(fun, x_init, args=4)\n",
    "optim_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 2.3881933437907206e-11\n",
       " hess_inv: array([[ 0.51923086, -0.09615402],\n",
       "       [-0.09615402,  0.98076916]])\n",
       "      jac: array([ 2.14204335e-06, -9.52464809e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 20\n",
       "      nit: 3\n",
       "     njev: 5\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([20.00000106,  3.99999523])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_res = minimize(fun, x_init, args=10)\n",
    "optim_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но иногда встречаются функции-бяки :)\n",
    "\n",
    "$f(x_1, x_2, x_3) = 0.01 (x_1 - 0.5)^2 + |x_1^2 - x_2| + |x_1^2 - x_3|$\n",
    "\n",
    "в) найдите минимум этой функции устно\n",
    "\n",
    "г*) найдите минимум этой функции с помощью `minimize` (автор задачи тоже не знает решения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[0.03077755, 0.00094606, 0.00094727],\n",
       "       [0.03070671, 0.00094229, 0.00094293],\n",
       "       [0.03070712, 0.00094213, 0.0009429 ],\n",
       "       [0.03087131, 0.00095078, 0.00095323]]), array([0.00220291, 0.00220301, 0.00220318, 0.00220326]))\n",
       "           fun: 0.0022029130300699013\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 280\n",
       "           nit: 161\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([0.03077755, 0.00094606, 0.00094727])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def byaka(x):\n",
    "    \"\"\" известная неприятная функция \"\"\"\n",
    "    z = 0.01 * (x[0] - 0.5) ** 2 + abs(x[0] ** 2 - x[1]) + abs(x[0] ** 2 - x[2])\n",
    "    return z\n",
    "\n",
    "x_init = [0, 0, 0]\n",
    "optim_res = minimize(byaka, x_init, method='powell')\n",
    "optim_res = minimize(byaka, x_init, method='bfgs')\n",
    "optim_res = minimize(byaka, x_init, method='nelder-mead')\n",
    "optim_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "д) нарисуйте функцию бяку "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачутка 2. Велика ты, правда, широка стоишь! Ты горами поднялась до поднебесья!\n",
    "\n",
    "(с) Алексей Толстой\n",
    "\n",
    "[Как известно](https://www.livelib.ru/quote/305456-malysh-i-karlson-kotoryj-zhivet-na-kryshe-astrid-lindgren), Фрекен Бок пьёт коньяк по утрам.\n",
    "\n",
    "![](http://semyarf.com/UPLOAD/2016/01/21/frekenbok-216_700_0.jpg)\n",
    "\n",
    "А у нас даже есть дневные данные (в граммах):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [3.2, 7.9, 5.4, 4.9, 6.2, 4.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а) Предполагая, что $y_i$ независимы и нормальны $N(\\mu, \\sigma^2)$ выпишите функцию правдоподобия.\n",
    "\n",
    "Чтобы гарантировать положительность параметра $\\sigma^2$ функция у нас будет зависеть от вектора параметров $\\theta$, причем $\\theta_1 = \\mu$, а $\\theta_2 = \\ln \\sigma^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minus_lklh(theta, y):\n",
    "    # theta_1 = mu\n",
    "    mu = theta[0] \n",
    "    # theta_2 = log(sigma^2) \n",
    "    s2 = np.exp(theta[1]) # лайфхак для неотрицательности sigma^2\n",
    "    n = len(y)\n",
    "    lklh = - 0.5 * n * np.log(s2) - 0.5 * np.sum((y - mu) ** 2) / s2\n",
    "    return -lklh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "б) Найдите экстремум функции правдоподобия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5819683626297953, 3.5000002497146308, 0.2750002585914815)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_init = [0, 0]\n",
    "y = [3.4, 2.7, 3.8, 4.1]\n",
    "\n",
    "optim_res = minimize(minus_lklh, theta_init, args=y)\n",
    "optim_res.fun, optim_res.x[0], np.exp(optim_res.x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в) Получите тот же результат используя встроенный метод `stats.norm.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.4999999999999996, 0.2749999999999998)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, sigma = stats.norm.fit(y)\n",
    "sigma2 = sigma ** 2\n",
    "mu, sigma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачулечка 3. \n",
    "\n",
    "А ещё Фрекен-Бок иногда видит привидения! Данные по количеству привидений у нас тоже есть :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbock = pd.DataFrame({'y': [3.2, 7.9, 5.4, 4.9, 6.2, 4.3], 'ghost': [1, 2, 0, 0, 2, 0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что количество привидений имеет пуассоновское распределение с параметром $\\lambda$. \n",
    "\n",
    "а) Оцените $\\lambda$ с помощью ММП:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.9116077839764465, array([0.83333469]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minus_lklh(theta, ghost):\n",
    "    rate = np.exp(theta) # тот же трюк, чтобы лямбда никогда не стала отрицательной\n",
    "    log_probs = -rate + ghost * np.log(rate) # про минус log(k!) забиваем!\n",
    "    lklh = np.sum(log_probs)\n",
    "    return -lklh\n",
    "\n",
    "theta_init = 0\n",
    "\n",
    "optim_res = minimize(minus_lklh, theta_init, args=fbock['ghost'])\n",
    "optim_res.fun, np.exp(optim_res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что в $i$-й день интенсивность пуассоновского распределения $\\lambda_i$ связана с количеством выпитого коньяка формулой $\\lambda_i = \\exp(a + b y_i)$.\n",
    "\n",
    "б) Оцените параметры $a$ и $b$, лапками выписав функцию правдоподобия. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.901374802427522, array([-2.59878425,  0.41696008]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minus_lklh(theta, fbock):\n",
    "    a = theta[0] # распакуем параметры для читабельности\n",
    "    b = theta[1]\n",
    "    rate = np.exp(a + b * fbock['y']) # тот же трюк, чтобы лямбда никогда не стала отрицательной\n",
    "    log_probs = -rate + fbock['ghost'] * np.log(rate) # про минус log(k!) забиваем!\n",
    "    lklh = np.sum(log_probs)\n",
    "    return -lklh\n",
    "\n",
    "theta_init = [0, 0]\n",
    "\n",
    "optim_res = minimize(minus_lklh, theta_init, args=fbock)\n",
    "optim_res.fun, optim_res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель является довольно популярной и реализована в `statsmodels`.\n",
    "\n",
    "в) Сравните ваши результаты с результатами в `statsmodels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.047945\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Poisson Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>ghost</td>      <th>  No. Observations:  </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                <td>Poisson</td>     <th>  Df Residuals:      </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 25 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.1384</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>01:38:59</td>     <th>  Log-Likelihood:    </th> <td> -6.2877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -7.2979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.1552</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -2.5988</td> <td>    1.918</td> <td>   -1.355</td> <td> 0.175</td> <td>   -6.358</td> <td>    1.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y</th>         <td>    0.4170</td> <td>    0.297</td> <td>    1.404</td> <td> 0.160</td> <td>   -0.165</td> <td>    0.999</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Poisson Regression Results                          \n",
       "==============================================================================\n",
       "Dep. Variable:                  ghost   No. Observations:                    6\n",
       "Model:                        Poisson   Df Residuals:                        4\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Mon, 25 May 2020   Pseudo R-squ.:                  0.1384\n",
       "Time:                        01:38:59   Log-Likelihood:                -6.2877\n",
       "converged:                       True   LL-Null:                       -7.2979\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1552\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -2.5988      1.918     -1.355      0.175      -6.358       1.161\n",
       "y              0.4170      0.297      1.404      0.160      -0.165       0.999\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.poisson(data=fbock, formula='ghost ~ 1 + y').fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачушка 4\n",
    "\n",
    "Предположим другую вероятностную модель. Теперь мы будем предполагать, что сам факт обнаружения хотя бы одного приведения, имеет вероятность $p_i$, зависящую от $y_i$:\n",
    "\n",
    "$p_i = \\exp(a + b y_i) / (1 + \\exp(a + b y_i))$\n",
    "\n",
    "а) Введите дамми-переменную равную 1, если Фрекен Бок видела приведение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbock['atleast1'] = 1 * (fbock['ghost'] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "б) Определив лапками функцию правдоподобия, оцените $a$ и $b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.8709632618137633, array([-2.35157624,  0.44383861]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minus_lklh(theta, fbock):\n",
    "    a = theta[0] # распакуем параметры для читабельности\n",
    "    b = theta[1]\n",
    "    p = np.exp(a + b * fbock['y']) / (1 + np.exp(a + b * fbock['y']))\n",
    "    log_probs = fbock['atleast1'] * np.log(p) + (1 - fbock['atleast1']) * np.log(1 - p)\n",
    "    lklh = np.sum(log_probs)\n",
    "    return -lklh\n",
    "\n",
    "theta_init = [0, 0]\n",
    "\n",
    "optim_res = minimize(minus_lklh, theta_init, args=fbock)\n",
    "optim_res.fun, optim_res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в) Оцените $a$ и $b$ с помощью `statsmodels`. Нужная модель называется `logit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.645161\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>atleast1</td>     <th>  No. Observations:  </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 25 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.06923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>01:45:29</td>     <th>  Log-Likelihood:    </th> <td> -3.8710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -4.1589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.4479</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -2.3516</td> <td>    3.376</td> <td>   -0.697</td> <td> 0.486</td> <td>   -8.969</td> <td>    4.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y</th>         <td>    0.4438</td> <td>    0.620</td> <td>    0.716</td> <td> 0.474</td> <td>   -0.772</td> <td>    1.660</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               atleast1   No. Observations:                    6\n",
       "Model:                          Logit   Df Residuals:                        4\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Mon, 25 May 2020   Pseudo R-squ.:                 0.06923\n",
       "Time:                        01:45:29   Log-Likelihood:                -3.8710\n",
       "converged:                       True   LL-Null:                       -4.1589\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.4479\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -2.3516      3.376     -0.697      0.486      -8.969       4.266\n",
       "y              0.4438      0.620      0.716      0.474      -0.772       1.660\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.logit(data=fbock, formula='atleast1 ~ 1 + y').fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
